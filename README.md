<h1 align="center"> NHáº¬N DIá»†N HÃ€NH VI Báº O Lá»°C TRONG ÄÃM ÄÃ”NG Báº°NG CNN 3D</h1>

<div align="center">
  
  <p align="center">
    <img src="./logoDaiNam.png" alt="Dai Nam Logo" width="200"/>
    <img src="./LogoAIoTLab.png" alt="AIoTLab Logo" width="200"/>
  </p>

[![Made by AIoTLab](https://img.shields.io/badge/Made%20by%20AIoTLab-blue?style=for-the-badge)](https://www.facebook.com/DNUAIoTLab)
[![Fit DNU](https://img.shields.io/badge/Fit%20DNU-green?style=for-the-badge)](https://fitdnu.net/)
[![DaiNam University](https://img.shields.io/badge/DaiNam%20University-red?style=for-the-badge)](https://dainam.edu.vn)

</div>

<h2 align="center">ğŸ’¡ Nháº­n diá»‡n hÃ nh vi báº¡o lá»±c trong Ä‘Ã¡m Ä‘Ã´ng</h2>
    Kho lÆ°u trá»¯ nÃ y chá»©a má»™t mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ phÃ¡t hiá»‡n báº¡o lá»±c trong luá»“ng video. MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Máº¡ng nÆ¡-ron tÃ­ch cháº­p 3D (CNN) vÃ  Ä‘Æ°á»£c Ä‘Ã o táº¡o Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c clip video thÃ nh "Báº¡o lá»±c" hoáº·c "KhÃ´ng báº¡o lá»±c".
<p align="left">
  
</p>

---

## ğŸ“¦Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#gioi-thieu)
- [Há»‡ thá»‘ng](#he-thong)
- [ThÆ° viá»‡n](#thu-vien)
- [Huáº¥n luyá»‡n mÃ´ hÃ¬nh](#huan-luyen-mo-hinh)
- [Cháº¡y mÃ´ hÃ¬nh](#chay-mo-hinh)
- [CÃ´ng cá»¥ sá»­ dá»¥ng](#cong-cu-su-dung)
- [Poster](#poster)
- [ÄÃ³ng gÃ³p](#dong-gop)

## ğŸŒŸGiá»›i thiá»‡u

Má»¥c tiÃªu cá»§a dá»± Ã¡n nÃ y lÃ  phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng phÃ¡t hiá»‡n báº¡o lá»±c thá»i gian thá»±c báº±ng mÃ´ hÃ¬nh CNN 3D. MÃ´ hÃ¬nh xá»­ lÃ½ cÃ¡c khung hÃ¬nh video vÃ  dá»± Ä‘oÃ¡n liá»‡u video cÃ³ chá»©a cÃ¡c hoáº¡t Ä‘á»™ng báº¡o lá»±c hay khÃ´ng.

## ğŸš€Há»‡ thá»‘ng

<div align="center">
    <img src="./architecture.png" alt="Dai Nam Logo" width="800" height="400"/>
</div>

```python
model = Sequential([
    Conv3D(32, kernel_size=(3,3,3), activation="relu", input_shape=(16, 224, 224, 3)),
    MaxPooling3D(pool_size=(1,2,2)),
    Conv3D(64, kernel_size=(3,3,3), activation="relu"),
    MaxPooling3D(pool_size=(1,2,2)),
    Conv3D(128, kernel_size=(3,3,3), activation="relu"),
    MaxPooling3D(pool_size=(2,2,2)),
    Flatten(),
    Dense(256, activation="relu"),
    Dropout(0.5),
    Dense(1, activation="sigmoid")
])
```

## ğŸ“–ThÆ° viá»‡n

pip install tensorflow opencv-python numpy playsound

## ğŸ› ï¸Huáº­n luyá»‡n mÃ´ hÃ¬nh

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# Load dataset
dataset_path = "./dataset"
X, y = load_dataset(dataset_path)

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize data
X_train, X_test = X_train / 255.0, X_test / 255.0

# Build model
model = Sequential([
    Conv3D(32, kernel_size=(3,3,3), activation="relu", input_shape=(16, 224, 224, 3)),
    MaxPooling3D(pool_size=(1,2,2)),
    Conv3D(64, kernel_size=(3,3,3), activation="relu"),
    MaxPooling3D(pool_size=(1,2,2)),
    Conv3D(128, kernel_size=(3,3,3), activation="relu"),
    MaxPooling3D(pool_size=(2,2,2)),
    Flatten(),
    Dense(256, activation="relu"),
    Dropout(0.5),
    Dense(1, activation="sigmoid")
])

model.compile(optimizer=Adam(learning_rate=0.0001), loss="binary_crossentropy", metrics=["accuracy"])

# Train model
model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))

# Save model
model.save("violence_detection_model.h5")
```

## ğŸ’»Cháº¡y mÃ´ hÃ¬nh

```python
import cv2
import numpy as np
import tensorflow as tf
import os
import time
from playsound import playsound
import threading

# Load trained model
model = tf.keras.models.load_model("./violence_detection_model.h5")

# Camera RTSP URL
rtsp_url = "rtsp://admin:RAJVMI@192.168.1.12:554/h264_stream"

# Connect to camera
cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 16)
cap.set(cv2.CAP_PROP_FPS, 16)

if not cap.isOpened():
    print("Cannot connect to camera.")
    exit()

save_path = "saved_frames"
if not os.path.exists(save_path):
    os.makedirs(save_path)

frame_size = (96, 96)
frame_count = 30
violence_threshold = 0.95
alarm_sound = "./clock-alarm.mp3"

frames = []
violence_frames = []

def play_alarm():
    playsound(alarm_sound)

while True:
    ret, frame = cap.read()
    if not ret:
        print("Error reading frame from camera.")
        break

    frame_display = cv2.resize(frame, (800, 600))
    cv2.putText(frame_display, "Monitoring", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

    frame_resized = cv2.resize(frame, frame_size)
    frame_resized = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
    frame_resized = frame_resized / 255.0

    frames.append(frame_resized)

    if len(frames) == frame_count:
        video_clip = np.array(frames, dtype=np.float32)
        video_clip = np.expand_dims(video_clip, axis=0)

        prediction = model.predict(video_clip)
        violence_prob = prediction[0, 0]
        label = "Violence" if violence_prob > violence_threshold else "Non-Violence"
        color = (0, 0, 255) if violence_prob > violence_threshold else (0, 255, 0)

        cv2.putText(frame_display, f"Prediction: {label}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        print(f"Prediction: {label} - Violence: {violence_prob:.2f}")

        if violence_prob > violence_threshold:
            threading.Thread(target=play_alarm, daemon=True).start()

        frames = frames[-4:]

    cv2.imshow("Camera", frame_display)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

## âš™ï¸CÃ´ng cá»¥ sá»­ dá»¥ng

**_TensorFlow_**:https://www.tensorflow.org/

**_OpenCV_**:https://opencv.org/

**_NumPy_**:https://numpy.org/

**_playsound_**:https://github.com/TaylorSMarks/playsound

**_Sklearn_**:https://scikit-learn.org/stable/

## ğŸ“°Poster

<div align="center">
    <img src="./Poster01.png" alt="Dai Nam Logo"/>
</div>

## ğŸ¤ÄÃ³ng gÃ³p

Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi 3 thÃ nh viÃªn:

<table>
        <thead>
            <tr>
                <th style="text-align:center">Há» vÃ  TÃªn</th>
                <th colspan="4" style="text-align:center">Vai TrÃ²</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Nguyá»…n Ãnh CÆ°Æ¡ng</td>
                <td>PhÃ¡t triá»ƒn toÃ n bá»™ mÃ£ nguá»“n, kiá»ƒm thá»­, triá»ƒn khai dá»± Ã¡n.</td>
            </tr>
            <tr>
                <td>VÅ© KhÃ¡nh HoÃ n</td>
                <td>BiÃªn soáº¡n tÃ i liá»‡u Overleaf, Poster, Powerpoint, thuyáº¿t trÃ¬nh, thá»±c hiá»‡n video giá»›i thiá»‡u 
                    vÃ  há»— trá»£ bÃ i táº­p lá»›n.</td>
            </tr>
            <tr>
                <td>NÃ´ng Trung Hiáº¿u</td>
                <td>BiÃªn soáº¡n tÃ i liá»‡u Overleaf, Thiáº¿t káº¿ slide.</td>
            </tr>
        </tbody>
</table>

2025 NHÃ“M 9, CNTT16-02, TRÆ¯á»œNG Äáº I Há»ŒC Äáº I NAM
